[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notes",
    "section": "",
    "text": "Préface\nQuelques notes de travail.",
    "crumbs": [
      "Préface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Intro.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Résumé",
    "section": "",
    "text": "En résumé, ce livre ne contient pas encore grand-chose.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Résumé</span>"
    ]
  },
  {
    "objectID": "sysdyn.html",
    "href": "sysdyn.html",
    "title": "3  Systèmes dynamiques",
    "section": "",
    "text": "3.1 Équations différentielles\nUn système dynamique est une formalisation mathématique permettant de décrire l’évolution de l’état d’un système dans le temps. Les trois composantes fondamentales sont :\nSi l’opérateur d’évolution ne dépend que du temps, on peut écrire : \\[\n\\dot{x}_t = f(t, x_t)\n\\] qui est une équation différentielle1 ordinaire (EDO) du premier ordre. L’EDO définit la trajectoire d’un point dans un espace d’états de dimension finie.\nHabituellement, on considère que la fonction \\(f\\), appelée champ de vecteurs, est connue et l’objectif est alors de calculer les trajectoires des points dans l’espace d’états (la fonction \\(x\\) est l’inconnue). Il s’agit de faire de la prédiction à partir de conditions initiales. Se posent alors les questions de l’existence, d’unicité ou de stabilité des trajectoires. En apprentissage, la configuration est typiquement inversée : on considère un ensemble de points d’apprentissage et on souhaite estimer une fonction \\(f\\) qui prédit au mieux les observations.\nDans le cas où la fonction inconnue \\(x\\) dépend de plusieurs variables (comme le temps et les coordonnées spatiales), on parlera d’équation différentielle partielle (EDP). C’est le cas lorsque l’on souhaite modéliser un système qui varie à la fois dans le temps et dans l’espace. L’état du système \\(x_t\\) est alors une fonction définie sur le domaine spatial. L’ensemble de toutes les fonctions possibles est appelé espace fonctionnel. Une EDP décrit alors l’évolution d’un système dynamique en dimension infinie.\nTransport optimal : la carte de transport optimal est le gradient d’une fonction convexe.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Systèmes dynamiques</span>"
    ]
  },
  {
    "objectID": "sysdyn.html#équations-différentielles",
    "href": "sysdyn.html#équations-différentielles",
    "title": "3  Systèmes dynamiques",
    "section": "",
    "text": "1 Les équations différentielles apparaissent avec l’invention du calcul infinitésimal par Isaac Newton et Gottfried Leibniz.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Systèmes dynamiques</span>"
    ]
  },
  {
    "objectID": "sysdyn.html#flot-de-gradient",
    "href": "sysdyn.html#flot-de-gradient",
    "title": "3  Systèmes dynamiques",
    "section": "3.2 Flot de gradient",
    "text": "3.2 Flot de gradient\nUn flot de gradient est un système dynamique dissipatif défini par une EDO de la forme \\(\\dot{x}_t = -\\nabla V(x_t)\\). La trajectoire suit alors la direction de la plus forte pente descendante de la fonction potentielle \\(V\\) (qui est une fonction de Lyapunov). La discrétisation numérique via un schéma d’Euler explicite correspond à l’algorithme de descente de gradient.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Systèmes dynamiques</span>"
    ]
  },
  {
    "objectID": "sysdyn.html#évolution-dune-densité",
    "href": "sysdyn.html#évolution-dune-densité",
    "title": "3  Systèmes dynamiques",
    "section": "3.3 Évolution d’une densité",
    "text": "3.3 Évolution d’une densité\nL’évolution d’une densité de probabilité \\(\\rho_t\\) transportée par un champ de vecteurs \\(v_t\\) est décrite par l’équation de continuité (EDP) : \\[\n\\frac{\\partial \\rho_t}{\\partial t} + \\operatorname{div} (\\rho_t v_t) = 0 \\ .\n\\] Dans le cadre du transport optimal, la formule de Benamou-Brenier montre que le chemin le plus court entre deux densités est celui qui minimise l’énergie cinétique totale tout en satisfaisant cette EDP.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Systèmes dynamiques</span>"
    ]
  },
  {
    "objectID": "sysdyn.html#flot-de-gradient-de-wasserstein",
    "href": "sysdyn.html#flot-de-gradient-de-wasserstein",
    "title": "3  Systèmes dynamiques",
    "section": "3.4 Flot de gradient de Wasserstein",
    "text": "3.4 Flot de gradient de Wasserstein\nSi on souhaite étendre la notion de flot de gradient (définie pour un point) à une densité de probabilité \\(\\rho_t\\), on obtient le flot de gradient de Wasserstein. Dans ce contexte, on cherche l’évolution de \\(\\rho_t\\) qui va minimiser une fonctionnelle d’énergie \\(F[\\rho]\\), c’st à dire le champ de vitesse suivant : \\[\nv_t = - \\nabla \\left( \\frac{\\delta F[\\rho_t]}{\\delta \\rho} \\right) \\ .\n\\] En considérant la contrainte de l’équation de continuité, on obtient l’EDP suivante : \\[\n\\frac{\\partial \\rho_t}{\\partial t} = \\operatorname{div} \\left(\\rho_t \\nabla \\left( \\frac{\\delta F[\\rho_t]}{\\delta \\rho} \\right)\\right) \\ .\n\\]\nExemple : On peut par exemple choisir pour \\(F(\\rho)\\) l’intégrale de l’entropie de Boltzmann-Shannon : \\[\nF(\\rho) = \\int_{\\mathbb{R}^d} U(\\rho(x))dx\n\\] avec \\(U(s) = s \\ln(s)\\). La variation première (notée \\(\\frac{\\delta F}{\\delta \\rho}\\)) est égale à la dérivée de la fonction de densité \\(U\\) : \\[\n\\frac{\\delta F}{\\delta \\rho} = U'(\\rho) = \\ln(\\rho) + 1 \\ .\n\\] On calcule ensuite le gradient de ce potentiel dans l’espace physique \\(\\mathbb{R}^d\\) : \\[\n\\nabla \\left( \\frac{\\delta F}{\\delta \\rho} \\right) = \\nabla(\\ln \\rho + 1) = \\frac{\\nabla \\rho}{\\rho} \\ .\n\\] Ce terme représente la vitesse à laquelle les particules se déplacent pour minimiser l’entropie. Injecté dans l’équation de continuité, on obtient l’équation de la chaleur : \\[\n\\frac{\\partial \\rho_t}{\\partial t} = \\operatorname{div} (\\nabla \\rho) = \\Delta \\rho \\ .\n\\] La diffusion de la chaleur correspond donc à une descente de gradient de l’entropie dans l’espace de Wasserstein. Le flux de chaleur est donc le chemin le plus court (géodésique) pour dissiper l’énergie libre2.\n2 Ce résultat a été démontré par Richard Jordan, David Kinderlehrer et Felix Otto dans l’article intitulé « The variational formulation of the Fokker-Planck equation », publié en 1998.L’EDP de flot de gradient de Wasserstein est souvent difficile à résoudre directement, on utilise en pratique le schéma de Jordan-Kinderlehrer-Otto (JKO), qui est l’analogue de la discrétisation par schéma d’Euler implicite pour les flots de gradient classiques. On construit donc une suite de densité \\((\\rho_k)\\) pour des pas de temps discrets. À chaque étape \\(k\\), connaissant la densité précédente \\(\\rho_{k−1}\\)​, la nouvelle densité \\(\\rho_k\\)​ est obtenue en résolvant le problème de minimisation variationnelle suivant : \\[\n\\rho_k = \\arg \\min_\\rho \\left( F(\\rho) + \\frac{1}{2\\tau}W^2_2(\\rho,\\rho_{k-1}) \\right) \\ .\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Systèmes dynamiques</span>"
    ]
  },
  {
    "objectID": "sysdyn.html#flow-matching",
    "href": "sysdyn.html#flow-matching",
    "title": "3  Systèmes dynamiques",
    "section": "3.5 Flow matching",
    "text": "3.5 Flow matching\nLe Flow Matching s’inscrit dans une perspective lagrangienne du transport de densité en s’intéressant au flot qui déplace chaque particule dont l’évolution est décrite par une EDO.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Systèmes dynamiques</span>"
    ]
  }
]